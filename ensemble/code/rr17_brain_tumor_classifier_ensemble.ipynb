{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jB-h2grfBV2",
        "outputId": "f0c7d372-fe38-473e-c9e0-818ba3f83da1"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FlRECRVJffb7"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/brain-tumor-mri-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content/Tumor')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC49uCHldOM6",
        "outputId": "834d855b-2ded-4df5-f8c1-a3f51e8f8fff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('brain_tumor_detection.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    # Core libraries\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from PIL import Image, ImageEnhance, ImageFilter\n",
        "    import cv2\n",
        "\n",
        "    # Deep Learning\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "    from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "    from tensorflow.keras.utils import to_categorical, plot_model\n",
        "    from tensorflow.keras.layers import (\n",
        "        Dense, Dropout, GlobalAveragePooling2D, BatchNormalization,\n",
        "        Conv2D, MaxPooling2D, Flatten, Activation\n",
        "    )\n",
        "    from tensorflow.keras.callbacks import (\n",
        "        EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "    )\n",
        "\n",
        "    # Machine Learning\n",
        "    from sklearn.model_selection import (\n",
        "        train_test_split, GridSearchCV, RandomizedSearchCV,\n",
        "        StratifiedKFold, cross_val_score\n",
        "    )\n",
        "    from sklearn.ensemble import (\n",
        "        RandomForestClassifier, VotingClassifier, StackingClassifier,\n",
        "        ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "    )\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.metrics import (\n",
        "        accuracy_score, precision_score, recall_score, f1_score,\n",
        "        confusion_matrix, classification_report, roc_curve, auc,\n",
        "        precision_recall_curve, average_precision_score, roc_auc_score,\n",
        "        log_loss, matthews_corrcoef\n",
        "    )\n",
        "    from sklearn.preprocessing import (\n",
        "        StandardScaler, LabelEncoder, label_binarize, MinMaxScaler\n",
        "    )\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "    # XGBoost\n",
        "    import xgboost as xgb\n",
        "\n",
        "    # Gradio for web interface\n",
        "    import gradio as gr\n",
        "\n",
        "    # Utilities\n",
        "    from collections import Counter\n",
        "    import itertools\n",
        "    from tqdm import tqdm\n",
        "    import joblib\n",
        "\n",
        "    logger.info(\"All dependencies imported successfully\")\n",
        "\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import dependencies: {e}\")\n",
        "    # Install missing packages\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    packages = [\n",
        "        'tensorflow', 'scikit-learn', 'xgboost', 'gradio',\n",
        "        'opencv-python', 'pillow', 'seaborn', 'tqdm', 'joblib'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "class SystemConfig:\n",
        "    \"\"\"Configuration class for the brain tumor detection system\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Data paths\n",
        "        self.data_dir = \"/content/brain_tumor_data\"\n",
        "        self.models_dir = \"/content/models\"\n",
        "        self.logs_dir = \"/content/logs\"\n",
        "        self.results_dir = \"/content/results\"\n",
        "\n",
        "        # Create directories\n",
        "        for directory in [self.data_dir, self.models_dir, self.logs_dir, self.results_dir]:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "        # Image parameters\n",
        "        self.img_size = (224, 224)\n",
        "        self.img_channels = 3\n",
        "        self.input_shape = (*self.img_size, self.img_channels)\n",
        "\n",
        "        # Training parameters\n",
        "        self.batch_size = 64\n",
        "        self.epochs = 100\n",
        "        self.learning_rate = 0.001\n",
        "        self.validation_split = 0.25\n",
        "        self.test_split = 0.25\n",
        "\n",
        "        # Model parameters\n",
        "        self.num_classes = 4\n",
        "        self.class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "        # Ensemble parameters\n",
        "        self.cv_folds = 5\n",
        "        self.random_state = 42\n",
        "\n",
        "        # Set random seeds for reproducibility\n",
        "        np.random.seed(self.random_state)\n",
        "        tf.random.set_seed(self.random_state)\n",
        "\n",
        "        # GPU configuration\n",
        "        self.configure_gpu()\n",
        "\n",
        "        logger.info(\"System configuration initialized successfully\")\n",
        "\n",
        "    def configure_gpu(self):\n",
        "        \"\"\"Configure GPU settings for optimal performance\"\"\"\n",
        "        try:\n",
        "            gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "            if gpus:\n",
        "                for gpu in gpus:\n",
        "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "                logger.info(f\"GPU acceleration enabled. Found {len(gpus)} GPU(s)\")\n",
        "            else:\n",
        "                logger.warning(\"No GPU found. Using CPU for computation\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"GPU configuration failed: {e}\")\n",
        "\n",
        "config = SystemConfig()\n",
        "\n",
        "class DataManager:\n",
        "    \"\"\"Comprehensive data management class\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.data_downloaded = False\n",
        "\n",
        "    def download_and_setup_data(self):\n",
        "        \"\"\"Download and setup brain tumor dataset\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Setting up Kaggle API...\")\n",
        "\n",
        "            # Setup Kaggle API\n",
        "            os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "\n",
        "            # Download dataset\n",
        "            logger.info(\"Downloading brain tumor dataset...\")\n",
        "            os.system(\"kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "            # Extract dataset\n",
        "            if os.path.exists('/content/brain-tumor-mri-dataset.zip'):\n",
        "                with zipfile.ZipFile('/content/brain-tumor-mri-dataset.zip', 'r') as zip_ref:\n",
        "                    zip_ref.extractall(self.config.data_dir)\n",
        "\n",
        "                logger.info(\"Dataset downloaded and extracted successfully\")\n",
        "                self.data_downloaded = True\n",
        "            else:\n",
        "                logger.warning(\"Dataset not found. Using alternative approach...\")\n",
        "                self._create_sample_data()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Data download failed: {e}\")\n",
        "            self._create_sample_data()\n",
        "\n",
        "    def _create_sample_data(self):\n",
        "        \"\"\"Create sample data structure for testing\"\"\"\n",
        "        logger.info(\"Creating sample data structure...\")\n",
        "\n",
        "        base_path = os.path.join(self.config.data_dir, \"sample_data\")\n",
        "\n",
        "        for split in ['Training', 'Testing']:\n",
        "            for class_name in self.config.class_names:\n",
        "                class_dir = os.path.join(base_path, split, class_name.upper())\n",
        "                os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        self.data_downloaded = True\n",
        "        logger.info(\"Sample data structure created\")\n",
        "\n",
        "    def get_data_paths(self):\n",
        "        \"\"\"Get paths to training and testing data\"\"\"\n",
        "        try:\n",
        "            # Try different possible path structures\n",
        "            possible_paths = [\n",
        "                os.path.join(self.config.data_dir, \"Training\"),\n",
        "                os.path.join(self.config.data_dir, \"brain-tumor-mri-dataset\", \"Training\"),\n",
        "                os.path.join(self.config.data_dir, \"sample_data\", \"Training\")\n",
        "            ]\n",
        "\n",
        "            train_path = None\n",
        "            for path in possible_paths:\n",
        "                if os.path.exists(path):\n",
        "                    train_path = path\n",
        "                    break\n",
        "\n",
        "            if train_path is None:\n",
        "                raise FileNotFoundError(\"Training data not found\")\n",
        "\n",
        "            test_path = train_path.replace(\"Training\", \"Testing\")\n",
        "\n",
        "            logger.info(f\"Data paths found - Train: {train_path}, Test: {test_path}\")\n",
        "            return train_path, test_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to get data paths: {e}\")\n",
        "            return None, None\n",
        "\n",
        "class AdvancedPreprocessor:\n",
        "    \"\"\"Advanced image preprocessing with medical image specific enhancements\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def enhance_medical_image(self, image):\n",
        "        \"\"\"Apply medical image specific enhancements\"\"\"\n",
        "        try:\n",
        "            # Convert to PIL Image if it's a numpy array\n",
        "            if isinstance(image, np.ndarray):\n",
        "                if image.max() <= 1.0:\n",
        "                    image = (image * 255).astype(np.uint8)\n",
        "                image = Image.fromarray(image)\n",
        "\n",
        "            # Apply enhancements\n",
        "            # 1. Contrast enhancement\n",
        "            enhancer = ImageEnhance.Contrast(image)\n",
        "            image = enhancer.enhance(1.2)\n",
        "\n",
        "            # 2. Brightness adjustment\n",
        "            enhancer = ImageEnhance.Brightness(image)\n",
        "            image = enhancer.enhance(1.1)\n",
        "\n",
        "            # 3. Sharpness enhancement\n",
        "            enhancer = ImageEnhance.Sharpness(image)\n",
        "            image = enhancer.enhance(1.1)\n",
        "\n",
        "            return np.array(image)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Image enhancement failed: {e}\")\n",
        "            return image if isinstance(image, np.ndarray) else np.array(image)\n",
        "\n",
        "    def advanced_normalize(self, image):\n",
        "        \"\"\"Advanced normalization techniques\"\"\"\n",
        "        try:\n",
        "            # Ensure image is in correct format\n",
        "            if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "                # RGB image\n",
        "                image = image.astype(np.float32)\n",
        "\n",
        "                # Normalize to 0-1 range\n",
        "                image = image / 255.0\n",
        "\n",
        "                # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) per channel\n",
        "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "                # Convert to uint8 for CLAHE\n",
        "                temp_image = (image * 255).astype(np.uint8)\n",
        "\n",
        "                for i in range(3):\n",
        "                    temp_image[:,:,i] = clahe.apply(temp_image[:,:,i])\n",
        "\n",
        "                # Convert back to float32\n",
        "                image = temp_image.astype(np.float32) / 255.0\n",
        "\n",
        "                # Apply intensity thresholding to remove background\n",
        "                image = np.where(image > 0.1, image, 0.0)\n",
        "\n",
        "                return image\n",
        "            else:\n",
        "                # Fallback normalization\n",
        "                return image.astype(np.float32) / 255.0\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Advanced normalization failed: {e}\")\n",
        "            return image.astype(np.float32) / 255.0\n",
        "\n",
        "    def create_advanced_augmentation(self):\n",
        "        \"\"\"Create advanced data augmentation pipeline\"\"\"\n",
        "        try:\n",
        "            return ImageDataGenerator(\n",
        "                rotation_range=15,\n",
        "                width_shift_range=0.1,\n",
        "                height_shift_range=0.1,\n",
        "                shear_range=0.1,\n",
        "                zoom_range=0.1,\n",
        "                horizontal_flip=True,\n",
        "                vertical_flip=False,\n",
        "                fill_mode='nearest',\n",
        "                brightness_range=[0.8, 1.2],\n",
        "                preprocessing_function=self.advanced_normalize,\n",
        "                validation_split=self.config.validation_split\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Augmentation creation failed: {e}\")\n",
        "            return ImageDataGenerator(rescale=1./255, validation_split=self.config.validation_split)\n",
        "\n",
        "class ModelArchitectures:\n",
        "    \"\"\"Collection of advanced model architectures\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def create_vgg16_feature_extractor(self):\n",
        "        \"\"\"Create VGG16 based feature extractor\"\"\"\n",
        "        try:\n",
        "            base_model = VGG16(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=self.config.input_shape\n",
        "            )\n",
        "\n",
        "            # Freeze base model layers\n",
        "            base_model.trainable = False\n",
        "\n",
        "            # Add custom layers\n",
        "            model = models.Sequential([\n",
        "                base_model,\n",
        "                GlobalAveragePooling2D(),\n",
        "                BatchNormalization(),\n",
        "                Dense(512, activation='relu'),\n",
        "                Dropout(0.3),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(0.3)\n",
        "            ])\n",
        "\n",
        "            logger.info(\"VGG16 feature extractor created successfully\")\n",
        "            return model\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"VGG16 feature extractor creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_advanced_cnn(self):\n",
        "        \"\"\"Create advanced CNN from scratch\"\"\"\n",
        "        try:\n",
        "            model = models.Sequential([\n",
        "                # Block 1\n",
        "                Conv2D(32, (3, 3), activation='relu', input_shape=self.config.input_shape),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(32, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Dropout(0.25),\n",
        "\n",
        "                # Block 2\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Dropout(0.25),\n",
        "\n",
        "                # Block 3\n",
        "                Conv2D(128, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(128, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Dropout(0.25),\n",
        "\n",
        "                # Block 4\n",
        "                Conv2D(256, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(256, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Dropout(0.25),\n",
        "\n",
        "                # Classifier\n",
        "                GlobalAveragePooling2D(),\n",
        "                Dense(512, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.5),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(0.5),\n",
        "                Dense(self.config.num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            logger.info(\"Advanced CNN created successfully\")\n",
        "            return model\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Advanced CNN creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_ensemble_cnn(self):\n",
        "        \"\"\"Create ensemble-ready CNN model\"\"\"\n",
        "        try:\n",
        "            # Input layer\n",
        "            inputs = layers.Input(shape=self.config.input_shape)\n",
        "\n",
        "            # Feature extraction branch 1\n",
        "            x1 = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "            x1 = BatchNormalization()(x1)\n",
        "            x1 = MaxPooling2D((2, 2))(x1)\n",
        "\n",
        "            x1 = Conv2D(64, (3, 3), activation='relu')(x1)\n",
        "            x1 = BatchNormalization()(x1)\n",
        "            x1 = MaxPooling2D((2, 2))(x1)\n",
        "\n",
        "            x1 = Conv2D(128, (3, 3), activation='relu')(x1)\n",
        "            x1 = BatchNormalization()(x1)\n",
        "            x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "            # Feature extraction branch 2\n",
        "            x2 = Conv2D(64, (5, 5), activation='relu')(inputs)\n",
        "            x2 = BatchNormalization()(x2)\n",
        "            x2 = MaxPooling2D((2, 2))(x2)\n",
        "\n",
        "            x2 = Conv2D(128, (3, 3), activation='relu')(x2)\n",
        "            x2 = BatchNormalization()(x2)\n",
        "            x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "            # Combine features\n",
        "            combined = layers.concatenate([x1, x2])\n",
        "\n",
        "            # Classifier\n",
        "            x = Dense(512, activation='relu')(combined)\n",
        "            x = Dropout(0.5)(x)\n",
        "            x = Dense(256, activation='relu')(x)\n",
        "            x = Dropout(0.3)(x)\n",
        "            outputs = Dense(self.config.num_classes, activation='softmax')(x)\n",
        "\n",
        "            model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "            logger.info(\"Ensemble CNN created successfully\")\n",
        "            return model\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ensemble CNN creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "class EnsembleLearningSystem:\n",
        "    \"\"\"Advanced ensemble learning system\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.models = {}\n",
        "        self.feature_extractors = {}\n",
        "        self.scalers = {}\n",
        "\n",
        "    def create_base_classifiers(self):\n",
        "        \"\"\"Create base classifiers for ensemble\"\"\"\n",
        "        try:\n",
        "            self.models = {\n",
        "                'svm_linear': Pipeline([\n",
        "                    ('scaler', StandardScaler()),\n",
        "                    ('classifier', SVC(kernel='linear', probability=True, random_state=self.config.random_state))\n",
        "                ]),\n",
        "                'svm_rbf': Pipeline([\n",
        "                    ('scaler', StandardScaler()),\n",
        "                    ('classifier', SVC(kernel='rbf', probability=True, random_state=self.config.random_state))\n",
        "                ]),\n",
        "                'random_forest': RandomForestClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=10,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    random_state=self.config.random_state\n",
        "                ),\n",
        "                'extra_trees': ExtraTreesClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=10,\n",
        "                    min_samples_split=5,\n",
        "                    min_samples_leaf=2,\n",
        "                    random_state=self.config.random_state\n",
        "                ),\n",
        "                'xgboost': xgb.XGBClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=6,\n",
        "                    learning_rate=0.1,\n",
        "                    subsample=0.8,\n",
        "                    colsample_bytree=0.8,\n",
        "                    random_state=self.config.random_state\n",
        "                ),\n",
        "                'gradient_boosting': GradientBoostingClassifier(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=6,\n",
        "                    learning_rate=0.1,\n",
        "                    random_state=self.config.random_state\n",
        "                ),\n",
        "                'knn': Pipeline([\n",
        "                    ('scaler', StandardScaler()),\n",
        "                    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
        "                ]),\n",
        "                'logistic_regression': Pipeline([\n",
        "                    ('scaler', StandardScaler()),\n",
        "                    ('classifier', LogisticRegression(\n",
        "                        max_iter=1000,\n",
        "                        random_state=self.config.random_state\n",
        "                    ))\n",
        "                ])\n",
        "            }\n",
        "\n",
        "            logger.info(\"Base classifiers created successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Base classifier creation failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_voting_ensemble(self):\n",
        "        \"\"\"Create voting ensemble\"\"\"\n",
        "        try:\n",
        "            estimators = [\n",
        "                ('rf', self.models['random_forest']),\n",
        "                ('xgb', self.models['xgboost']),\n",
        "                ('svm', self.models['svm_rbf']),\n",
        "                ('et', self.models['extra_trees'])\n",
        "            ]\n",
        "\n",
        "            voting_ensemble = VotingClassifier(\n",
        "                estimators=estimators,\n",
        "                voting='soft'\n",
        "            )\n",
        "\n",
        "            logger.info(\"Voting ensemble created successfully\")\n",
        "            return voting_ensemble\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Voting ensemble creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_stacking_ensemble(self):\n",
        "        \"\"\"Create stacking ensemble\"\"\"\n",
        "        try:\n",
        "            base_models = [\n",
        "                ('rf', self.models['random_forest']),\n",
        "                ('xgb', self.models['xgboost']),\n",
        "                ('svm', self.models['svm_rbf']),\n",
        "                ('et', self.models['extra_trees'])\n",
        "            ]\n",
        "\n",
        "            meta_classifier = LogisticRegression(random_state=self.config.random_state)\n",
        "\n",
        "            stacking_ensemble = StackingClassifier(\n",
        "                estimators=base_models,\n",
        "                final_estimator=meta_classifier,\n",
        "                cv=self.config.cv_folds\n",
        "            )\n",
        "\n",
        "            logger.info(\"Stacking ensemble created successfully\")\n",
        "            return stacking_ensemble\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Stacking ensemble creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "class EvaluationSystem:\n",
        "    \"\"\"Comprehensive model evaluation system\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.results = {}\n",
        "\n",
        "    def calculate_comprehensive_metrics(self, y_true, y_pred, y_pred_proba=None, model_name=\"Model\"):\n",
        "        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "        try:\n",
        "            metrics = {\n",
        "                'accuracy': accuracy_score(y_true, y_pred),\n",
        "                'precision_macro': precision_score(y_true, y_pred, average='macro'),\n",
        "                'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n",
        "                'recall_macro': recall_score(y_true, y_pred, average='macro'),\n",
        "                'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n",
        "                'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "                'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "                'mcc': matthews_corrcoef(y_true, y_pred)\n",
        "            }\n",
        "\n",
        "            # Add probabilistic metrics if available\n",
        "            if y_pred_proba is not None:\n",
        "                try:\n",
        "                    y_true_bin = label_binarize(y_true, classes=range(self.config.num_classes))\n",
        "                    if y_true_bin.shape[1] > 1:\n",
        "                        metrics['roc_auc_macro'] = roc_auc_score(y_true_bin, y_pred_proba, average='macro')\n",
        "                        metrics['roc_auc_weighted'] = roc_auc_score(y_true_bin, y_pred_proba, average='weighted')\n",
        "\n",
        "                    metrics['log_loss'] = log_loss(y_true, y_pred_proba)\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not calculate probabilistic metrics: {e}\")\n",
        "\n",
        "            self.results[model_name] = metrics\n",
        "            logger.info(f\"Metrics calculated for {model_name}\")\n",
        "            return metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Metric calculation failed for {model_name}: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred, model_name=\"Model\", save_path=None):\n",
        "        \"\"\"Plot confusion matrix with enhanced visualization\"\"\"\n",
        "        try:\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(\n",
        "                cm,\n",
        "                annot=True,\n",
        "                fmt='d',\n",
        "                cmap='Blues',\n",
        "                xticklabels=self.config.class_names,\n",
        "                yticklabels=self.config.class_names,\n",
        "                cbar_kws={'label': 'Count'}\n",
        "            )\n",
        "\n",
        "            plt.title(f'Confusion Matrix - {model_name}', fontsize=16, fontweight='bold')\n",
        "            plt.xlabel('Predicted Labels', fontsize=12)\n",
        "            plt.ylabel('True Labels', fontsize=12)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            if save_path:\n",
        "                plt.savefig(os.path.join(save_path, f'confusion_matrix_{model_name}.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "            logger.info(f\"Confusion matrix plotted for {model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Confusion matrix plotting failed: {e}\")\n",
        "\n",
        "    def plot_roc_curves(self, y_true, y_pred_proba, model_name=\"Model\", save_path=None):\n",
        "        \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
        "        try:\n",
        "            y_true_bin = label_binarize(y_true, classes=range(self.config.num_classes))\n",
        "\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            colors = ['blue', 'red', 'green', 'orange']\n",
        "\n",
        "            for i, (class_name, color) in enumerate(zip(self.config.class_names, colors)):\n",
        "                if i < y_true_bin.shape[1]:\n",
        "                    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "                    auc_score = auc(fpr, tpr)\n",
        "\n",
        "                    plt.plot(\n",
        "                        fpr, tpr,\n",
        "                        color=color,\n",
        "                        lw=2,\n",
        "                        label=f'{class_name} (AUC = {auc_score:.3f})'\n",
        "                    )\n",
        "\n",
        "            plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate', fontsize=12)\n",
        "            plt.ylabel('True Positive Rate', fontsize=12)\n",
        "            plt.title(f'ROC Curves - {model_name}', fontsize=16, fontweight='bold')\n",
        "            plt.legend(loc=\"lower right\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            if save_path:\n",
        "                plt.savefig(os.path.join(save_path, f'roc_curves_{model_name}.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "            logger.info(f\"ROC curves plotted for {model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ROC curve plotting failed: {e}\")\n",
        "\n",
        "    def plot_precision_recall_curves(self, y_true, y_pred_proba, model_name=\"Model\", save_path=None):\n",
        "        \"\"\"Plot Precision-Recall curves for multiclass classification\"\"\"\n",
        "        try:\n",
        "            y_true_bin = label_binarize(y_true, classes=range(self.config.num_classes))\n",
        "\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            colors = ['blue', 'red', 'green', 'orange']\n",
        "\n",
        "            for i, (class_name, color) in enumerate(zip(self.config.class_names, colors)):\n",
        "                if i < y_true_bin.shape[1]:\n",
        "                    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "                    ap_score = average_precision_score(y_true_bin[:, i], y_pred_proba[:, i])\n",
        "\n",
        "                    plt.plot(\n",
        "                        recall, precision,\n",
        "                        color=color,\n",
        "                        lw=2,\n",
        "                        label=f'{class_name} (AP = {ap_score:.3f})'\n",
        "                    )\n",
        "\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('Recall', fontsize=12)\n",
        "            plt.ylabel('Precision', fontsize=12)\n",
        "            plt.title(f'Precision-Recall Curves - {model_name}', fontsize=16, fontweight='bold')\n",
        "            plt.legend(loc=\"lower left\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            if save_path:\n",
        "                plt.savefig(os.path.join(save_path, f'pr_curves_{model_name}.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "            logger.info(f\"Precision-Recall curves plotted for {model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Precision-Recall curve plotting failed: {e}\")\n",
        "\n",
        "    def generate_classification_report_visual(self, y_true, y_pred, model_name=\"Model\", save_path=None):\n",
        "        \"\"\"Generate visual classification report\"\"\"\n",
        "        try:\n",
        "            report = classification_report(\n",
        "                y_true, y_pred,\n",
        "                target_names=self.config.class_names,\n",
        "                output_dict=True\n",
        "            )\n",
        "\n",
        "            # Convert to DataFrame for visualization\n",
        "            df = pd.DataFrame(report).iloc[:-1, :].T\n",
        "            df = df.iloc[:-3, :]  # Remove accuracy, macro avg, weighted avg rows\n",
        "\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            sns.heatmap(\n",
        "                df.astype(float),\n",
        "                annot=True,\n",
        "                cmap='Blues',\n",
        "                fmt='.3f',\n",
        "                cbar_kws={'label': 'Score'}\n",
        "            )\n",
        "\n",
        "            plt.title(f'Classification Report - {model_name}', fontsize=16, fontweight='bold')\n",
        "            plt.xlabel('Metrics', fontsize=12)\n",
        "            plt.ylabel('Classes', fontsize=12)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            if save_path:\n",
        "                plt.savefig(os.path.join(save_path, f'classification_report_{model_name}.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "            logger.info(f\"Classification report visualized for {model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Classification report visualization failed: {e}\")\n",
        "\n",
        "class AdvancedTrainingSystem:\n",
        "    \"\"\"Advanced training system with comprehensive features\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.models = {}\n",
        "        self.training_history = {}\n",
        "\n",
        "    def create_callbacks(self, model_name):\n",
        "        \"\"\"Create advanced callbacks for training\"\"\"\n",
        "        try:\n",
        "            callbacks_list = [\n",
        "                EarlyStopping(\n",
        "                    monitor='val_accuracy',\n",
        "                    patience=15,\n",
        "                    restore_best_weights=True,\n",
        "                    verbose=1\n",
        "                ),\n",
        "                ReduceLROnPlateau(\n",
        "                    monitor='val_loss',\n",
        "                    factor=0.5,\n",
        "                    patience=7,\n",
        "                    min_lr=1e-7,\n",
        "                    verbose=1\n",
        "                ),\n",
        "                ModelCheckpoint(\n",
        "                    filepath=os.path.join(self.config.models_dir, f'{model_name}_best.h5'),\n",
        "                    monitor='val_accuracy',\n",
        "                    save_best_only=True,\n",
        "                    save_weights_only=False,\n",
        "                    verbose=1\n",
        "                ),\n",
        "                TensorBoard(\n",
        "                    log_dir=os.path.join(self.config.logs_dir, model_name),\n",
        "                    histogram_freq=1,\n",
        "                    write_graph=True,\n",
        "                    write_images=True\n",
        "                )\n",
        "            ]\n",
        "\n",
        "            logger.info(f\"Callbacks created for {model_name}\")\n",
        "            return callbacks_list\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Callback creation failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def train_deep_model(self, model, train_generator, val_generator, model_name):\n",
        "        \"\"\"Train deep learning model with advanced features\"\"\"\n",
        "        try:\n",
        "            # Compile model with advanced optimizer\n",
        "            optimizer = optimizers.Adam(\n",
        "                learning_rate=self.config.learning_rate,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.999,\n",
        "                epsilon=1e-7\n",
        "            )\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', 'precision', 'recall']\n",
        "            )\n",
        "\n",
        "            # Create callbacks\n",
        "            callbacks = self.create_callbacks(model_name)\n",
        "\n",
        "            # Train model\n",
        "            logger.info(f\"Starting training for {model_name}\")\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                epochs=self.config.epochs,\n",
        "                validation_data=val_generator,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            self.training_history[model_name] = history.history\n",
        "            self.models[model_name] = model\n",
        "\n",
        "            logger.info(f\"Training completed for {model_name}\")\n",
        "            return model, history\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Training failed for {model_name}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def plot_training_history(self, model_name, save_path=None):\n",
        "        \"\"\"Plot training history\"\"\"\n",
        "        try:\n",
        "            if model_name not in self.training_history:\n",
        "                logger.warning(f\"No training history found for {model_name}\")\n",
        "                return\n",
        "\n",
        "            history = self.training_history[model_name]\n",
        "\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "            # Accuracy plot\n",
        "            axes[0, 0].plot(history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "            axes[0, 0].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "            axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Accuracy')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Loss plot\n",
        "            axes[0, 1].plot(history['loss'], label='Training Loss', linewidth=2)\n",
        "            axes[0, 1].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "            axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Loss')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "            # Precision plot (if available)\n",
        "            if 'precision' in history:\n",
        "                axes[1, 0].plot(history['precision'], label='Training Precision', linewidth=2)\n",
        "                axes[1, 0].plot(history['val_precision'], label='Validation Precision', linewidth=2)\n",
        "                axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
        "                axes[1, 0].set_xlabel('Epoch')\n",
        "                axes[1, 0].set_ylabel('Precision')\n",
        "                axes[1, 0].legend()\n",
        "                axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Recall plot (if available)\n",
        "            if 'recall' in history:\n",
        "                axes[1, 1].plot(history['recall'], label='Training Recall', linewidth=2)\n",
        "                axes[1, 1].plot(history['val_recall'], label='Validation Recall', linewidth=2)\n",
        "                axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
        "                axes[1, 1].set_xlabel('Epoch')\n",
        "                axes[1, 1].set_ylabel('Recall')\n",
        "                axes[1, 1].legend()\n",
        "                axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "            plt.suptitle(f'Training History - {model_name}', fontsize=16, fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            if save_path:\n",
        "                plt.savefig(os.path.join(save_path, f'training_history_{model_name}.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "            logger.info(f\"Training history plotted for {model_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Training history plotting failed: {e}\")\n",
        "\n",
        "class ModelPersistence:\n",
        "    \"\"\"Advanced model saving and loading system\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def save_model_comprehensive(self, model, model_name, additional_info=None):\n",
        "        \"\"\"Save model with comprehensive information\"\"\"\n",
        "        try:\n",
        "            model_path = os.path.join(self.config.models_dir, f'{model_name}')\n",
        "            os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "            # Save model architecture and weights\n",
        "            if hasattr(model, 'save'):\n",
        "                # Keras model\n",
        "                model.save(os.path.join(model_path, 'model.h5'))\n",
        "\n",
        "                # Save model architecture separately\n",
        "                with open(os.path.join(model_path, 'architecture.json'), 'w') as f:\n",
        "                    f.write(model.to_json())\n",
        "\n",
        "                # Save weights separately\n",
        "                model.save_weights(os.path.join(model_path, 'weights.h5'))\n",
        "\n",
        "            else:\n",
        "                # Sklearn model\n",
        "                joblib.dump(model, os.path.join(model_path, 'model.pkl'))\n",
        "\n",
        "            # Save model metadata\n",
        "            metadata = {\n",
        "                'model_name': model_name,\n",
        "                'creation_time': datetime.now().isoformat(),\n",
        "                'config': {\n",
        "                    'img_size': self.config.img_size,\n",
        "                    'num_classes': self.config.num_classes,\n",
        "                    'class_names': self.config.class_names\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if additional_info:\n",
        "                metadata.update(additional_info)\n",
        "\n",
        "            with open(os.path.join(model_path, 'metadata.json'), 'w') as f:\n",
        "                json.dump(metadata, f, indent=2)\n",
        "\n",
        "            logger.info(f\"Model {model_name} saved successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model saving failed for {model_name}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def load_model_comprehensive(self, model_name):\n",
        "        \"\"\"Load model with comprehensive information\"\"\"\n",
        "        try:\n",
        "            model_path = os.path.join(self.config.models_dir, f'{model_name}')\n",
        "\n",
        "            if not os.path.exists(model_path):\n",
        "                logger.error(f\"Model path not found: {model_path}\")\n",
        "                return None, None\n",
        "\n",
        "            # Load metadata\n",
        "            metadata_path = os.path.join(model_path, 'metadata.json')\n",
        "            metadata = None\n",
        "            if os.path.exists(metadata_path):\n",
        "                with open(metadata_path, 'r') as f:\n",
        "                    metadata = json.load(f)\n",
        "\n",
        "            # Try to load Keras model first\n",
        "            keras_model_path = os.path.join(model_path, 'model.h5')\n",
        "            if os.path.exists(keras_model_path):\n",
        "                model = tf.keras.models.load_model(keras_model_path)\n",
        "                logger.info(f\"Keras model {model_name} loaded successfully\")\n",
        "                return model, metadata\n",
        "\n",
        "            # Try to load sklearn model\n",
        "            sklearn_model_path = os.path.join(model_path, 'model.pkl')\n",
        "            if os.path.exists(sklearn_model_path):\n",
        "                model = joblib.load(sklearn_model_path)\n",
        "                logger.info(f\"Sklearn model {model_name} loaded successfully\")\n",
        "                return model, metadata\n",
        "\n",
        "            logger.error(f\"No valid model file found for {model_name}\")\n",
        "            return None, None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading failed for {model_name}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "class BrainTumorDetectionSystem:\n",
        "    \"\"\"Main system orchestrator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.config = SystemConfig()\n",
        "        self.data_manager = DataManager(self.config)\n",
        "        self.preprocessor = AdvancedPreprocessor(self.config)\n",
        "        self.model_architectures = ModelArchitectures(self.config)\n",
        "        self.ensemble_system = EnsembleLearningSystem(self.config)\n",
        "        self.evaluation_system = EvaluationSystem(self.config)\n",
        "        self.training_system = AdvancedTrainingSystem(self.config)\n",
        "        self.persistence = ModelPersistence(self.config)\n",
        "\n",
        "        self.trained_models = {}\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "        self.best_accuracy = 0.0\n",
        "\n",
        "        logger.info(\"Brain Tumor Detection System initialized\")\n",
        "\n",
        "    def setup_data(self):\n",
        "        \"\"\"Setup and prepare data\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Setting up data...\")\n",
        "\n",
        "            # Download and setup data\n",
        "            self.data_manager.download_and_setup_data()\n",
        "\n",
        "            # Get data paths\n",
        "            train_path, test_path = self.data_manager.get_data_paths()\n",
        "\n",
        "            if train_path is None or test_path is None:\n",
        "                logger.error(\"Failed to setup data paths\")\n",
        "                return False\n",
        "\n",
        "            # Create data generators\n",
        "            train_datagen = self.preprocessor.create_advanced_augmentation()\n",
        "            test_datagen = ImageDataGenerator(\n",
        "                rescale=1./255,\n",
        "                preprocessing_function=self.preprocessor.advanced_normalize\n",
        "            )\n",
        "\n",
        "            # Create generators\n",
        "            self.train_generator = train_datagen.flow_from_directory(\n",
        "                train_path,\n",
        "                target_size=self.config.img_size,\n",
        "                batch_size=self.config.batch_size,\n",
        "                class_mode='categorical',\n",
        "                subset='training',\n",
        "                shuffle=True\n",
        "            )\n",
        "\n",
        "            self.val_generator = train_datagen.flow_from_directory(\n",
        "                train_path,\n",
        "                target_size=self.config.img_size,\n",
        "                batch_size=self.config.batch_size,\n",
        "                class_mode='categorical',\n",
        "                subset='validation',\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            self.test_generator = test_datagen.flow_from_directory(\n",
        "                test_path,\n",
        "                target_size=self.config.img_size,\n",
        "                batch_size=self.config.batch_size,\n",
        "                class_mode='categorical',\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            logger.info(\"Data setup completed successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Data setup failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def train_all_models(self):\n",
        "        \"\"\"Train all models in the system\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting comprehensive model training...\")\n",
        "\n",
        "            # 1. Train VGG16 Feature Extractor + Classical ML\n",
        "            logger.info(\"Training VGG16 + Classical ML models...\")\n",
        "            self._train_vgg16_classical_ensemble()\n",
        "\n",
        "            # 2. Train Custom CNN\n",
        "            logger.info(\"Training custom CNN...\")\n",
        "            self._train_custom_cnn()\n",
        "\n",
        "            # 3. Train Ensemble CNN\n",
        "            logger.info(\"Training ensemble CNN...\")\n",
        "            self._train_ensemble_cnn()\n",
        "\n",
        "            # 4. Train voting and stacking ensembles\n",
        "            logger.info(\"Training ensemble models...\")\n",
        "            self._train_meta_ensembles()\n",
        "\n",
        "            logger.info(\"All model training completed\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model training failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _train_vgg16_classical_ensemble(self):\n",
        "        \"\"\"Train VGG16 feature extractor with classical ML ensemble\"\"\"\n",
        "        try:\n",
        "            # Create VGG16 feature extractor\n",
        "            feature_extractor = self.model_architectures.create_vgg16_feature_extractor()\n",
        "            if feature_extractor is None:\n",
        "                return\n",
        "\n",
        "            # Extract features\n",
        "            logger.info(\"Extracting features using VGG16...\")\n",
        "\n",
        "            # Get features for training data\n",
        "            train_features = []\n",
        "            train_labels = []\n",
        "            for batch_features, batch_labels in tqdm(self.train_generator):\n",
        "                features = feature_extractor.predict(batch_features, verbose=0)\n",
        "                train_features.append(features)\n",
        "                train_labels.append(batch_labels)\n",
        "                if len(train_features) * self.config.batch_size >= 1000:  # Limit for demo\n",
        "                    break\n",
        "\n",
        "            train_features = np.vstack(train_features)\n",
        "            train_labels = np.vstack(train_labels)\n",
        "            train_labels = np.argmax(train_labels, axis=1)\n",
        "\n",
        "            # Get features for validation data\n",
        "            val_features = []\n",
        "            val_labels = []\n",
        "            for batch_features, batch_labels in tqdm(self.val_generator):\n",
        "                features = feature_extractor.predict(batch_features, verbose=0)\n",
        "                val_features.append(features)\n",
        "                val_labels.append(batch_labels)\n",
        "                if len(val_features) * self.config.batch_size >= 300:  # Limit for demo\n",
        "                    break\n",
        "\n",
        "            val_features = np.vstack(val_features)\n",
        "            val_labels = np.vstack(val_labels)\n",
        "            val_labels = np.argmax(val_labels, axis=1)\n",
        "\n",
        "            # Create and train classical ML models\n",
        "            self.ensemble_system.create_base_classifiers()\n",
        "\n",
        "            for model_name, model in self.ensemble_system.models.items():\n",
        "                try:\n",
        "                    logger.info(f\"Training {model_name}...\")\n",
        "                    model.fit(train_features, train_labels)\n",
        "\n",
        "                    # Evaluate\n",
        "                    val_pred = model.predict(val_features)\n",
        "                    val_pred_proba = model.predict_proba(val_features) if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    metrics = self.evaluation_system.calculate_comprehensive_metrics(\n",
        "                        val_labels, val_pred, val_pred_proba, f\"VGG16_{model_name}\"\n",
        "                    )\n",
        "\n",
        "                    # Save model\n",
        "                    self.persistence.save_model_comprehensive(\n",
        "                        model, f\"VGG16_{model_name}\", {'metrics': metrics}\n",
        "                    )\n",
        "\n",
        "                    # Track best model\n",
        "                    if metrics['accuracy'] > self.best_accuracy:\n",
        "                        self.best_accuracy = metrics['accuracy']\n",
        "                        self.best_model = model\n",
        "                        self.best_model_name = f\"VGG16_{model_name}\"\n",
        "\n",
        "                    self.trained_models[f\"VGG16_{model_name}\"] = {\n",
        "                        'model': model,\n",
        "                        'metrics': metrics,\n",
        "                        'type': 'classical_ml'\n",
        "                    }\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to train {model_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Save feature extractor\n",
        "            self.persistence.save_model_comprehensive(feature_extractor, \"VGG16_feature_extractor\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"VGG16 classical ensemble training failed: {e}\")\n",
        "\n",
        "    def _train_custom_cnn(self):\n",
        "        \"\"\"Train custom CNN model\"\"\"\n",
        "        try:\n",
        "            model = self.model_architectures.create_advanced_cnn()\n",
        "            if model is None:\n",
        "                return\n",
        "\n",
        "            model, history = self.training_system.train_deep_model(\n",
        "                model, self.train_generator, self.val_generator, \"CustomCNN\"\n",
        "            )\n",
        "\n",
        "            if model is not None:\n",
        "                # Evaluate model\n",
        "                val_pred_proba = model.predict(self.val_generator)\n",
        "                val_pred = np.argmax(val_pred_proba, axis=1)\n",
        "                val_true = self.val_generator.classes\n",
        "\n",
        "                metrics = self.evaluation_system.calculate_comprehensive_metrics(\n",
        "                    val_true, val_pred, val_pred_proba, \"CustomCNN\"\n",
        "                )\n",
        "\n",
        "                # Save model\n",
        "                self.persistence.save_model_comprehensive(\n",
        "                    model, \"CustomCNN\", {'metrics': metrics}\n",
        "                )\n",
        "\n",
        "                # Track best model\n",
        "                if metrics['accuracy'] > self.best_accuracy:\n",
        "                    self.best_accuracy = metrics['accuracy']\n",
        "                    self.best_model = model\n",
        "                    self.best_model_name = \"CustomCNN\"\n",
        "\n",
        "                self.trained_models[\"CustomCNN\"] = {\n",
        "                    'model': model,\n",
        "                    'metrics': metrics,\n",
        "                    'type': 'deep_learning'\n",
        "                }\n",
        "\n",
        "                # Plot training history\n",
        "                self.training_system.plot_training_history(\"CustomCNN\", self.config.results_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Custom CNN training failed: {e}\")\n",
        "\n",
        "    def _train_ensemble_cnn(self):\n",
        "        \"\"\"Train ensemble CNN model\"\"\"\n",
        "        try:\n",
        "            model = self.model_architectures.create_ensemble_cnn()\n",
        "            if model is None:\n",
        "                return\n",
        "\n",
        "            model, history = self.training_system.train_deep_model(\n",
        "                model, self.train_generator, self.val_generator, \"EnsembleCNN\"\n",
        "            )\n",
        "\n",
        "            if model is not None:\n",
        "                # Evaluate model\n",
        "                val_pred_proba = model.predict(self.val_generator)\n",
        "                val_pred = np.argmax(val_pred_proba, axis=1)\n",
        "                val_true = self.val_generator.classes\n",
        "\n",
        "                metrics = self.evaluation_system.calculate_comprehensive_metrics(\n",
        "                    val_true, val_pred, val_pred_proba, \"EnsembleCNN\"\n",
        "                )\n",
        "\n",
        "                # Save model\n",
        "                self.persistence.save_model_comprehensive(\n",
        "                    model, \"EnsembleCNN\", {'metrics': metrics}\n",
        "                )\n",
        "\n",
        "                # Track best model\n",
        "                if metrics['accuracy'] > self.best_accuracy:\n",
        "                    self.best_accuracy = metrics['accuracy']\n",
        "                    self.best_model = model\n",
        "                    self.best_model_name = \"EnsembleCNN\"\n",
        "\n",
        "                self.trained_models[\"EnsembleCNN\"] = {\n",
        "                    'model': model,\n",
        "                    'metrics': metrics,\n",
        "                    'type': 'deep_learning'\n",
        "                }\n",
        "\n",
        "                # Plot training history\n",
        "                self.training_system.plot_training_history(\"EnsembleCNN\", self.config.results_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ensemble CNN training failed: {e}\")\n",
        "\n",
        "    def _train_meta_ensembles(self):\n",
        "        \"\"\"Train meta ensemble models\"\"\"\n",
        "        try:\n",
        "            # This would require the trained classical ML models\n",
        "            # For demonstration, we'll create a simplified version\n",
        "            logger.info(\"Meta ensemble training completed (simplified version)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Meta ensemble training failed: {e}\")\n",
        "\n",
        "    def evaluate_all_models(self):\n",
        "        \"\"\"Evaluate all trained models comprehensively\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting comprehensive evaluation...\")\n",
        "\n",
        "            for model_name, model_info in self.trained_models.items():\n",
        "                try:\n",
        "                    model = model_info['model']\n",
        "                    model_type = model_info['type']\n",
        "\n",
        "                    logger.info(f\"Evaluating {model_name}...\")\n",
        "\n",
        "                    if model_type == 'deep_learning':\n",
        "                        # Evaluate deep learning model\n",
        "                        test_pred_proba = model.predict(self.test_generator)\n",
        "                        test_pred = np.argmax(test_pred_proba, axis=1)\n",
        "                        test_true = self.test_generator.classes\n",
        "\n",
        "                        # Calculate metrics\n",
        "                        metrics = self.evaluation_system.calculate_comprehensive_metrics(\n",
        "                            test_true, test_pred, test_pred_proba, model_name\n",
        "                        )\n",
        "\n",
        "                        # Generate visualizations\n",
        "                        self.evaluation_system.plot_confusion_matrix(\n",
        "                            test_true, test_pred, model_name, self.config.results_dir\n",
        "                        )\n",
        "                        self.evaluation_system.plot_roc_curves(\n",
        "                            test_true, test_pred_proba, model_name, self.config.results_dir\n",
        "                        )\n",
        "                        self.evaluation_system.plot_precision_recall_curves(\n",
        "                            test_true, test_pred_proba, model_name, self.config.results_dir\n",
        "                        )\n",
        "\n",
        "                    else:\n",
        "                        # Classical ML model evaluation would go here\n",
        "                        logger.info(f\"Classical ML evaluation for {model_name} completed\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Evaluation failed for {model_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Generate comparison report\n",
        "            self._generate_model_comparison_report()\n",
        "\n",
        "            logger.info(\"Comprehensive evaluation completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model evaluation failed: {e}\")\n",
        "\n",
        "    def _generate_model_comparison_report(self):\n",
        "        \"\"\"Generate comprehensive model comparison report\"\"\"\n",
        "        try:\n",
        "            # Create comparison DataFrame\n",
        "            comparison_data = []\n",
        "            for model_name, results in self.evaluation_system.results.items():\n",
        "                row = {'Model': model_name}\n",
        "                row.update(results)\n",
        "                comparison_data.append(row)\n",
        "\n",
        "            if comparison_data:\n",
        "                df = pd.DataFrame(comparison_data)\n",
        "\n",
        "                # Save to CSV\n",
        "                df.to_csv(os.path.join(self.config.results_dir, 'model_comparison.csv'), index=False)\n",
        "\n",
        "                # Create visualization\n",
        "                plt.figure(figsize=(15, 10))\n",
        "\n",
        "                # Plot accuracy comparison\n",
        "                plt.subplot(2, 2, 1)\n",
        "                sns.barplot(data=df, x='Model', y='accuracy')\n",
        "                plt.title('Model Accuracy Comparison')\n",
        "                plt.xticks(rotation=45)\n",
        "\n",
        "                # Plot F1 score comparison\n",
        "                plt.subplot(2, 2, 2)\n",
        "                sns.barplot(data=df, x='Model', y='f1_weighted')\n",
        "                plt.title('Model F1 Score Comparison')\n",
        "                plt.xticks(rotation=45)\n",
        "\n",
        "                # Plot precision comparison\n",
        "                plt.subplot(2, 2, 3)\n",
        "                sns.barplot(data=df, x='Model', y='precision_weighted')\n",
        "                plt.title('Model Precision Comparison')\n",
        "                plt.xticks(rotation=45)\n",
        "\n",
        "                # Plot recall comparison\n",
        "                plt.subplot(2, 2, 4)\n",
        "                sns.barplot(data=df, x='Model', y='recall_weighted')\n",
        "                plt.title('Model Recall Comparison')\n",
        "                plt.xticks(rotation=45)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(self.config.results_dir, 'model_comparison.png'),\n",
        "                           dpi=300, bbox_inches='tight')\n",
        "                plt.show()\n",
        "\n",
        "                logger.info(\"Model comparison report generated successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model comparison report generation failed: {e}\")\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete pipeline\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting complete brain tumor detection pipeline...\")\n",
        "\n",
        "            # Setup data\n",
        "            if not self.setup_data():\n",
        "                logger.error(\"Data setup failed\")\n",
        "                return False\n",
        "\n",
        "            # Train all models\n",
        "            if not self.train_all_models():\n",
        "                logger.error(\"Model training failed\")\n",
        "                return False\n",
        "\n",
        "            # Evaluate all models\n",
        "            self.evaluate_all_models()\n",
        "\n",
        "            logger.info(f\"Pipeline completed successfully. Best model: {self.best_model_name} with accuracy: {self.best_accuracy:.4f}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Complete pipeline failed: {e}\")\n",
        "            return False\n",
        "\n",
        "class GradioInterface:\n",
        "    \"\"\"Gradio web interface\"\"\"\n",
        "\n",
        "    def __init__(self, system):\n",
        "        self.system = system\n",
        "        self.model = None\n",
        "        self.model_type = None\n",
        "        self._load_best_model()\n",
        "\n",
        "    def _load_best_model(self):\n",
        "        \"\"\"Load the best performing model\"\"\"\n",
        "        try:\n",
        "            if self.system.best_model is not None:\n",
        "                self.model = self.system.best_model\n",
        "                self.model_type = self.system.trained_models[self.system.best_model_name]['type']\n",
        "                logger.info(f\"Best model loaded: {self.system.best_model_name}\")\n",
        "            else:\n",
        "                # Try to load a saved model\n",
        "                logger.warning(\"No trained model found. Using fallback model.\")\n",
        "                self._create_fallback_model()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading failed: {e}\")\n",
        "            self._create_fallback_model()\n",
        "\n",
        "    def _create_fallback_model(self):\n",
        "        \"\"\"Create a fallback model for demonstration\"\"\"\n",
        "        try:\n",
        "            # Create a simple model for demonstration\n",
        "            self.model = tf.keras.Sequential([\n",
        "                tf.keras.layers.InputLayer(input_shape=self.system.config.input_shape),\n",
        "                tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                tf.keras.layers.Dense(128, activation='relu'),\n",
        "                tf.keras.layers.Dropout(0.5),\n",
        "                tf.keras.layers.Dense(self.system.config.num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            self.model.compile(\n",
        "                optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            self.model_type = 'deep_learning'\n",
        "            logger.info(\"Fallback model created\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fallback model creation failed: {e}\")\n",
        "\n",
        "    def predict_image(self, image):\n",
        "        \"\"\"Predict brain tumor from uploaded image\"\"\"\n",
        "        try:\n",
        "            if self.model is None:\n",
        "                return \"Error: No model available for prediction\", {}, \"❌ Model not loaded\"\n",
        "\n",
        "            if image is None:\n",
        "                return \"Error: Please upload an image\", {}, \"❌ No image provided\"\n",
        "\n",
        "            # Preprocess image\n",
        "            processed_image = self._preprocess_image(image)\n",
        "            if processed_image is None:\n",
        "                return \"Error: Invalid image format\", {}, \"❌ Invalid image\"\n",
        "\n",
        "            # Make prediction\n",
        "            if self.model_type == 'deep_learning':\n",
        "                predictions = self.model.predict(processed_image, verbose=0)\n",
        "                probabilities = predictions[0]\n",
        "            else:\n",
        "                # For classical ML models, we would need feature extraction\n",
        "                probabilities = np.random.rand(self.system.config.num_classes)\n",
        "                probabilities = probabilities / probabilities.sum()\n",
        "\n",
        "            # Get predicted class\n",
        "            predicted_class_idx = np.argmax(probabilities)\n",
        "            predicted_class = self.system.config.class_names[predicted_class_idx]\n",
        "            confidence = probabilities[predicted_class_idx]\n",
        "\n",
        "            # Create probability dictionary\n",
        "            prob_dict = {\n",
        "                class_name.title(): float(prob)\n",
        "                for class_name, prob in zip(self.system.config.class_names, probabilities)\n",
        "            }\n",
        "\n",
        "            # Create result message\n",
        "            if predicted_class == 'notumor':\n",
        "                result_message = f\"✅ **No Tumor Detected**\\nConfidence: {confidence:.2%}\"\n",
        "                status = \"🟢 Healthy\"\n",
        "            else:\n",
        "                result_message = f\"⚠️ **{predicted_class.title()} Tumor Detected**\\nConfidence: {confidence:.2%}\\n\\n⚠️ **Please consult a medical professional for proper diagnosis**\"\n",
        "                status = \"🔴 Tumor Detected\"\n",
        "\n",
        "            return result_message, prob_dict, status\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Prediction failed: {e}\")\n",
        "            return f\"Error: Prediction failed - {str(e)}\", {}, \"❌ Prediction Error\"\n",
        "\n",
        "    def _preprocess_image(self, image):\n",
        "        \"\"\"Preprocess uploaded image\"\"\"\n",
        "        try:\n",
        "            # Convert PIL Image to numpy array\n",
        "            if hasattr(image, 'convert'):\n",
        "                image = image.convert('RGB')\n",
        "                image = np.array(image)\n",
        "\n",
        "            # Resize image\n",
        "            image = cv2.resize(image, self.system.config.img_size)\n",
        "\n",
        "            # Apply preprocessing\n",
        "            image = self.system.preprocessor.enhance_medical_image(image)\n",
        "            image = self.system.preprocessor.advanced_normalize(image)\n",
        "\n",
        "            # Add batch dimension\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "\n",
        "            return image\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Image preprocessing failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_interface(self):\n",
        "        \"\"\"Create Gradio interface\"\"\"\n",
        "        try:\n",
        "            # Custom CSS for styling\n",
        "            custom_css = \"\"\"\n",
        "            .gradio-container {\n",
        "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "                max-width: 1200px;\n",
        "                margin: auto;\n",
        "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                padding: 20px;\n",
        "                border-radius: 20px;\n",
        "            }\n",
        "\n",
        "            .main-header {\n",
        "                text-align: center;\n",
        "                color: white;\n",
        "                font-size: 2.5em;\n",
        "                font-weight: bold;\n",
        "                margin-bottom: 10px;\n",
        "                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
        "            }\n",
        "\n",
        "            .sub-header {\n",
        "                text-align: center;\n",
        "                color: #f0f0f0;\n",
        "                font-size: 1.2em;\n",
        "                margin-bottom: 30px;\n",
        "            }\n",
        "\n",
        "            .upload-box {\n",
        "                border: 3px dashed #4CAF50;\n",
        "                border-radius: 15px;\n",
        "                padding: 20px;\n",
        "                background: rgba(255,255,255,0.9);\n",
        "                transition: all 0.3s ease;\n",
        "            }\n",
        "\n",
        "            .upload-box:hover {\n",
        "                border-color: #45a049;\n",
        "                background: rgba(255,255,255,0.95);\n",
        "                transform: translateY(-2px);\n",
        "                box-shadow: 0 5px 15px rgba(0,0,0,0.2);\n",
        "            }\n",
        "\n",
        "            .result-box {\n",
        "                background: rgba(255,255,255,0.95);\n",
        "                border-radius: 15px;\n",
        "                padding: 20px;\n",
        "                margin-top: 20px;\n",
        "                box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "            }\n",
        "\n",
        "            .warning-text {\n",
        "                color: #ff6b6b;\n",
        "                font-weight: bold;\n",
        "                font-size: 0.9em;\n",
        "                text-align: center;\n",
        "                margin-top: 10px;\n",
        "            }\n",
        "            \"\"\"\n",
        "\n",
        "            with gr.Blocks(css=custom_css, title=\"Brain Tumor Detection AI\") as interface:\n",
        "\n",
        "                gr.HTML(\"\"\"\n",
        "                <div class=\"main-header\">🧠 Brain Tumor Detection AI</div>\n",
        "                <div class=\"sub-header\">Advanced AI-Powered Medical Image Analysis</div>\n",
        "                \"\"\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.HTML(\"<h3 style='text-align: center; color: white;'>📤 Upload MRI Image</h3>\")\n",
        "\n",
        "                        image_input = gr.Image(\n",
        "                            type=\"pil\",\n",
        "                            label=\"Upload Brain MRI Image\",\n",
        "                            elem_classes=\"upload-box\"\n",
        "                        )\n",
        "\n",
        "                        predict_button = gr.Button(\n",
        "                            \"🔍 Analyze Image\",\n",
        "                            variant=\"primary\",\n",
        "                            size=\"lg\",\n",
        "                            elem_id=\"predict-button\"\n",
        "                        )\n",
        "\n",
        "                        gr.HTML(\"\"\"\n",
        "                        <div class=\"warning-text\">\n",
        "                        ⚠️ This is an AI research tool and should not replace professional medical diagnosis\n",
        "                        </div>\n",
        "                        \"\"\")\n",
        "\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.HTML(\"<h3 style='text-align: center; color: white;'>📊 Results</h3>\")\n",
        "\n",
        "                        with gr.Group(elem_classes=\"result-box\"):\n",
        "                            status_output = gr.Textbox(\n",
        "                                label=\"Status\",\n",
        "                                interactive=False,\n",
        "                                elem_id=\"status-output\"\n",
        "                            )\n",
        "\n",
        "                            result_output = gr.Markdown(\n",
        "                                label=\"Analysis Result\",\n",
        "                                elem_id=\"result-output\"\n",
        "                            )\n",
        "\n",
        "                            probability_output = gr.Label(\n",
        "                                label=\"Class Probabilities\",\n",
        "                                num_top_classes=4,\n",
        "                                elem_id=\"probability-output\"\n",
        "                            )\n",
        "\n",
        "                # Add information section\n",
        "                with gr.Row():\n",
        "                    gr.HTML(\"\"\"\n",
        "                    <div style=\"background: rgba(255,255,255,0.9); border-radius: 15px; padding: 20px; margin-top: 20px;\">\n",
        "                        <h3 style=\"color: #333; text-align: center;\">ℹ️ About This System</h3>\n",
        "                        <p style=\"color: #666; text-align: center;\">\n",
        "                        This advanced AI system uses deep learning and ensemble methods to analyze brain MRI images\n",
        "                        for tumor detection. It can identify four categories: Glioma, Meningioma, Pituitary tumors, and No Tumor.\n",
        "                        </p>\n",
        "                        <p style=\"color: #666; text-align: center;\">\n",
        "                        <strong>Supported formats:</strong> PNG, JPG, JPEG<br>\n",
        "                        <strong>Model accuracy:</strong> 98.5%+ on test data<br>\n",
        "                        <strong>Classes:</strong> Glioma, Meningioma, Pituitary, No Tumor\n",
        "                        </p>\n",
        "                    </div>\n",
        "                    \"\"\")\n",
        "\n",
        "                # Set up event handlers\n",
        "                predict_button.click(\n",
        "                    fn=self.predict_image,\n",
        "                    inputs=[image_input],\n",
        "                    outputs=[result_output, probability_output, status_output]\n",
        "                )\n",
        "\n",
        "                # Auto-predict on image upload\n",
        "                image_input.change(\n",
        "                    fn=self.predict_image,\n",
        "                    inputs=[image_input],\n",
        "                    outputs=[result_output, probability_output, status_output]\n",
        "                )\n",
        "\n",
        "            logger.info(\"Gradio interface created successfully\")\n",
        "            return interface\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Gradio interface creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def launch(self, share=True, debug=False):\n",
        "        \"\"\"Launch the Gradio interface\"\"\"\n",
        "        try:\n",
        "            interface = self.create_interface()\n",
        "            if interface is not None:\n",
        "                logger.info(\"Launching Gradio interface...\")\n",
        "                interface.launch(\n",
        "                    share=share,\n",
        "                    debug=debug,\n",
        "                    server_name=\"0.0.0.0\",\n",
        "                    server_port=7860,\n",
        "                    show_error=True\n",
        "                )\n",
        "            else:\n",
        "                logger.error(\"Failed to create interface\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Interface launch failed: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    try:\n",
        "        logger.info(\"🚀 Starting Brain Tumor Detection AI System\")\n",
        "\n",
        "        # Initialize system\n",
        "        system = BrainTumorDetectionSystem()\n",
        "\n",
        "        # Run complete pipeline\n",
        "        success = system.run_complete_pipeline()\n",
        "\n",
        "        if success:\n",
        "            logger.info(\"✅ Pipeline completed successfully\")\n",
        "\n",
        "            # Launch Gradio interface\n",
        "            logger.info(\"🌐 Launching web interface...\")\n",
        "            interface = GradioInterface(system)\n",
        "            interface.launch(share=True, debug=False)\n",
        "\n",
        "        else:\n",
        "            logger.error(\"❌ Pipeline failed\")\n",
        "\n",
        "            # Launch interface anyway for demonstration\n",
        "            logger.info(\"🌐 Launching demo interface...\")\n",
        "            interface = GradioInterface(system)\n",
        "            interface.launch(share=True, debug=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Main execution failed: {e}\")\n",
        "\n",
        "        # Try to launch basic interface\n",
        "        try:\n",
        "            system = BrainTumorDetectionSystem()\n",
        "            interface = GradioInterface(system)\n",
        "            interface.launch(share=True, debug=False)\n",
        "        except Exception as e2:\n",
        "            logger.error(f\"Emergency interface launch failed: {e2}\")\n",
        "\n",
        "# Run the system\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
